{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13 v\n",
    "1\n",
    "2\n",
    "3\n",
    "4\n",
    "5\n",
    "6\n",
    "8\n",
    "9\n",
    "11\n",
    "15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('corpus.txt')\n",
    "raw = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Описати, які класи стрічок відповідають наступному регулярному виразу. [a-zA-Z]+. Результати перевірити використовуючи nltk.re_show( )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{So}, {at} {the} {start} {of} 2012, {I} {set} {myself} {the} {challenge} {of} {trying} {to} {read} {a} {book} {from} {every} {country} ({well}, {all} 195 {UN}-{recognised} {states} {plus} {former} {UN} {member} {Taiwan}) {in} {a} {year} {to} {find} {out} {what} {I} {was} {missing}.{cat} {pat}\n"
     ]
    }
   ],
   "source": [
    "nltk.re_show('[a-zA-Z]+',raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Виділяє всі слова, які складаються з літер, але не виділяє цифри і розділові знаки.\n",
    "Цьому виразу відповідають стрічки довільної довжини, які складаються з великих та (або) малих літер."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Описати, які класи стрічок відповідають наступному регулярному виразу. [A-Z][a-z]*. Результати перевірити використовуючи nltk.re_show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{So}, at the start of 2012, {I} set myself the challenge of trying to read a book from every country (well, all 195 {U}{N}-recognised states plus former {U}{N} member {Taiwan}) in a year to find out what {I} was missing.cat pat\n"
     ]
    }
   ],
   "source": [
    "nltk.re_show('[A-Z][a-z]*',raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Виділяє лише слова, які починаються з великої літери.\n",
    "Цьому виразу відповідають стрічки, які складаються з однієї великої літери та 0 або більше малих літер."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Описати, які класи стрічок відповідають наступному регулярному виразу. \\d+(\\.\\d+)?. Результати перевірити використовуючи nltk.re_show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So, at the start of {2012}, I set myself the challenge of trying to read a book from every country (well, all {195} UN-recognised states plus former UN member Taiwan) in a year to find out what I was missing.cat pat\n"
     ]
    }
   ],
   "source": [
    "nltk.re_show ('\\d+(\\.\\d+)?', raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Виділяє послідовність цифр.Даному виразу відповідають усі можливі додатні числа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Описати, які класи стрічок відповідають наступному регулярному виразу. ([^aeiou][aeiou][^aeiou])*. Результати перевірити використовуючи nltk.re_show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{So, at}{} {}t{he }{}s{tar}{}t{ of}{} {}2{}0{}1{}2{},{} {}I{} {set}{} {}m{}y{sel}{}f{} {}t{he }{}c{hallenge }{}o{}f{} {}t{}r{yin}{}g{} {to }{}r{}e{}a{}d{ a }{}b{}o{}o{}k{} {}f{rom ev}{}e{}r{}y{} {}c{}o{}u{}n{}t{}r{}y{} {}({wel}{}l{},{ al}{}l{} {}1{}9{}5{} {}U{}N{}-{rec}{}o{}g{nis}{}e{}d{} {}s{tat}{}e{}s{} {}p{lus}{} {former}{} {}U{}N{} {member}{} {}T{}a{}i{wan}{}){ in a }{}y{}e{}a{}r{} {to fin}{}d{} {}o{}u{}t{} {}w{hat}{} {}I{} {was}{} {missin}{}g{}.{cat}{} {pat}{}\n"
     ]
    }
   ],
   "source": [
    " nltk.re_show ('([^aeiou][aeiou][^aeiou])*', raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Виділяється послідовності символів, що складаються з трьох символів, перший і третій з яких не є голосною, а другий – будь-яка голосна з [aeiou] і зустрічаються 0 і більше разів.\n",
    "Цьому виразу відповідають 0 або більше послідовностей не голосна-голосна-не голосна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Описати, які класи стрічок відповідають наступному регулярному виразу. \\w+|[^\\w\\s]+.. Результати перевірити використовуючи nltk.re_show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{So}{, }{at} {the} {start} {of} {2012}{, }{I} {set} {myself} {the} {challenge} {of} {trying} {to} {read} {a} {book} {from} {every} {country} {(w}{ell}{, }{all} {195} {UN}{-r}{ecognised} {states} {plus} {former} {UN} {member} {Taiwan}{) }{in} {a} {year} {to} {find} {out} {what} {I} {was} {missing}{.c}{at} {pat}\n"
     ]
    }
   ],
   "source": [
    "nltk.re_show ('\\w+|[^\\w\\s]+.', raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Виділяє всі слова, цифри та символи.Виразу \\w+|[^\\w\\s]+. відповідають стрічки, які складаються з довільної к-сті букв або цифр (\\w+), або з довільної к-сті не букв, цифр, пробілів ([^\\w\\s]+) і будь-якого символу (.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Описати, які класи стрічок відповідають наступному регулярному виразу. p[aeiou]{,2}t  Результати перевірити використовуючи nltk.re_show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So, at the start of 2012, I set myself the challenge of trying to read a book from every country (well, all 195 UN-recognised states plus former UN member Taiwan) in a year to find out what I was missing.cat {pat}\n"
     ]
    }
   ],
   "source": [
    "nltk.re_show ('p[aeiou]{,2}t', raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Виділяємо стрічку, які складаються з літери “p”, від 0 до 2 голосних і літери “t”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Написати регулярний вираз, який встановлює відповідністьнаступному класу стрічок:арифметичний вираз з цілими значеннями і, який містить операції множення та додавання (2*3+8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2*3+8', '5*2+2']\n"
     ]
    }
   ],
   "source": [
    "print (re.findall(r\"\\d+[+|*]\\d+[+|*]\\d+\", raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "арифметичний вираз з цілими значеннями і, який містить операції множення та додавання "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Зберегти довільний текст у файлі corpus.txt. Визначити функцію  для читання з цього файлу (назва файлу аргумент функції) і повертає стрічку, яка містить текст з файлу. Використовуючи nltk.regexp_tokenize() розробити токенізатор для токенізації різних типів пунктуації в цьому тексті. Використовувати багаторядковий запис регулярного виразу з коментарями та «verbose flag» \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT:\n",
      "So, at the start of 2012, I set myself the challenge of trying to read a book from every country (well, all 195 UN-recognised states plus former UN member Taiwan) in a year to find out what I was missing.cat pat\n",
      "1234567890\n",
      "(2*3+8)\n",
      "5*2+2\n",
      "A few days ago, Nathan Bierma asked me (by email) whether the construction exemplified by \"as best (as) I can\" might be a blend of \"the best (that) I can\" and \"as well as I can\". The puzzle is why we say \"as best (as) I can\", but not \"as hardest (as) I can\", or indeed \"as ___ (as) I can\" for any other superlative. \n",
      "Whatever the exact history, \"as best <SUBJ> <MODAL>\" is an old pattern. For instance, an anonymous drama from 1634, \"The Mirror of New Reformation\", has the lines\n",
      "... I wil straight dispose,  ",
      "as best I can, th'inferiour Magistrate ... \n",
      "And in \"The Taming of the Shrew\" (1594), Shakespeare has Petruchio say\n",
      "And I haue thrust my selfe into this maze,  ",
      "Happily to wiue and thriue, as best I may ... \n",
      "The pattern \"as best as\" seems to be more recent. The earlier citation I could find was from 1856, in \"Night and Morning\" (a play adapted from the novel by Bulwer-Lytton), where Gawtry says: \n",
      "In fine, my life is that of a great schoolboy, getting into scrapes for the fun of it, and fighting my way out as best as I can! \n",
      "It continues to be used by reputable authors, as in William Carlos Williams' poem 1917 poem \"Sympathetic Portrait of a Child\":\n",
      "As best as she can  ",
      "she hides herself  ",
      "in the full sunlight \n",
      "But whatever the origins and history of the construction, Nathan's suggestion might have something to do with the forces that keep it in current use. So I thought I'd look at some current web counts; and since different search engines sometimes give counts that differ in random-seeming ways, I tried MSN, Yahoo and Google. I started by looking at the patterns \"as best __ can\" and \"as best as __ can\", across the different pronouns. I might still discover something relevant to Nathan's question, but along the way I stumbled on a strange pattern in the web search count, which I'll share with you now.\n",
      "TOKENIZED TEXT\n",
      "[' at', ' ', 't', 'he ', 's', 'tar', 't', ' of', ' ', '2', '0', '1', '2', ',', ' ', 'I', ' ', 'set', ' ', 'm', 'y', 'sel', 'f', ' ', 't', 'he ', 'c', 'ge ', 'o', 'f', ' ', 't', 'r', 'yin', 'g', ' ', 'to ', 'r', 'e', 'a', 'd', ' a ', 'b', 'o', 'o', 'k', ' ', 'f', ' ev', 'e', 'r', 'y', ' ', 'c', 'o', 'u', 'n', 't', 'r', 'y', ' ', '(', 'wel', 'l', ',', ' al', 'l', ' ', '1', '9', '5', ' ', 'U', 'N', '-', 'rec', 'o', 'g', 'nis', 'e', 'd', ' ', 's', 'tat', 'e', 's', ' ', 'p', 'lus', ' ', 'mer', ' ', 'U', 'N', ' ', 'ber', ' ', 'T', 'a', 'i', 'wan', ')', ' a ', 'y', 'e', 'a', 'r', ' ', 'fin', 'd', ' ', 'o', 'u', 't', ' ', 'w', 'hat', ' ', 'I', ' ', 'was', ' ', 'sin', 'g', '.', 'cat', ' ', 'pat', '\\n', '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', '\\n', '(', '2', '*', '3', '+', '8', ')', '\\n', '5', '*', '2', '+', '2', '\\n', 'A', ' ', 'few', ' ', 'day', 's', ' ag', 'o', ',', ' ', 'han', ' ', 'B', 'i', 'e', 'r', 'ma ', 'a', 's', 'ked', ' ', 'me ', '(', 'b', 'y', ' em', 'a', 'i', 'l', ')', ' ', 'w', 'her', ' ', 't', 'con', 's', 't', 'ruc', 't', 'i', 'o', 'n', ' ex', 'e', 'm', 'p', 'lif', 'i', 'e', 'd', ' ', 'b', 'y', ' ', '\"as', ' ', 'bes', 't', ' ', '(as', ')', ' ', 'I', ' ', 'can', '\"', ' ', 'mig', 'h', 't', ' ', 'be ', 'a', ' ', 'b', 'len', 'd', ' of', ' ', '\"', 't', 'bes', 't', ' ', '(', 't', 'hat', ')', ' ', 'I', ' ', 'can', '\"', ' an', 'd', ' ', '\"as', ' ', 'wel', 'l', ' as', ' ', 'I', ' ', 'can', '\"', '.', ' ', 'T', 'puz', 'z', 'le ', 'i', 's', ' ', 'w', 'h', 'y', ' ', 'say', ' ', '\"as', ' ', 'bes', 't', ' ', '(as', ')', ' ', 'I', ' ', 'can', '\"', ',', ' ', 'but', ' ', 'not', ' ', '\"as', ' ', 'des', 't', ' ', '(as', ')', ' ', 'I', ' ', 'can', '\"', ',', ' in', 'd', 'e', 'e', 'd', ' ', '\"as', ' ', '_', '_', '_', ' ', '(as', ')', ' ', 'I', ' ', 'can', '\"', ' ', ' an', 'y', 'her', ' ', 'sup', 'e', 'r', 'lat', 'i', 've.', ' ', '\\n', 'W', 'hat', 'e', 'ver', ' ', 't', 'he ', 'e', 'xac', 't', ' ', 'tor', 'y', ',', ' ', '\"as', ' ', 'bes', 't', ' ', '<', 'S', 'U', 'B', 'J', '>', ' ', '<', 'M', 'O', 'D', 'A', 'L', '>', '\"', ' ol', 'd', ' ', 'ter', 'n', '.', ' ', ' in', 's', ' an', 'o', 'n', 'y', 'm', 'o', 'u', 's', ' ', 'd', 'ram', 'a', ' ', 'f', 'rom', ' ', '1', '6', '3', '4', ',', ' ', '\"', 'T', ' of', ' ', 'New', ' ', 'Ref', 'o', 'r', 'mat', 'i', 'o', 'n', '\"', ',', ' ', 'has', ' ', 't', 'lin', 'e', 's', '\\n', '.', '.', '.', ' ', 'I', ' ', 'wil', ' ', 's', 't', 'r', 'a', 'i', 'g', 'h', 't', ' ', 'pos', 'e', ',', ' ', '\\u2028as', ' ', 'bes', 't', ' ', 'I', ' ', 'can', ',', ' ', 't', 'h', 'fer', 'i', 'o', 'u', 'r', ' ', 'Mag', 'i', 's', 't', 'rat', 'e', ' ', '.', '.', '.', ' ', '\\n', 'A', 'n', 'd', ' in', ' ', '\"', 'T', 'Tam', 'i', 'n', 'g', ' of', ' ', 't', 'he ', 'S', 'h', 'rew', '\"', ' ', '(', '1', '5', '9', '4', ')', ',', ' ', 'S', 'hak', 'e', 's', 'p', 'e', 'a', 'has', ' ', 'ruc', 'h', 'i', 'o', ' ', 'say', '\\n', 'A', 'n', 'd', ' ', 'I', ' ', 'h', 'a', 'u', 'e', ' ', 't', 'h', 'rus', 't', ' ', 'm', 'y', ' ', 'fe ', 'i', 'n', 'to ', 't', 'his', ' ', 'maz', 'e', ',', ' ', '\\u2028', 'pil', 'y', ' ', 'to ', 'w', 'i', 'u', 'e', ' an', 'd', ' ', 't', 'h', 'r', 'i', 'u', 'e', ',', ' as', ' ', 'bes', 't', ' ', 'I', ' ', 'may', ' ', '.', '.', '.', ' ', '\\n', 'T', 'ter', 'n', ' ', '\"as', ' ', 'bes', 't', ' as', '\"', ' ', 's', 'e', 'e', 'm', 's', ' ', 'mor', 'e', ' ', 'rec', 'e', 'n', 't', '.', ' ', 'T', 'he ', 'e', 'a', 'r', 'l', 'i', 'e', 'r', ' ', 'cit', 'a', 't', 'i', 'o', 'n', ' ', 'I', ' ', 'c', 'o', 'u', 'l', 'd', ' ', 'fin', 'd', ' ', 'was', ' ', 'f', 'rom', ' ', '1', '8', '5', '6', ',', ' in', ' ', '\"', 'Nig', 'h', 't', ' an', 'd', ' ', 'nin', 'g', '\"', ' ', '(a ', 'p', ' ad', 'a', 'p', 'ted', ' ', 'f', 'rom', ' ', 't', 'nov', 'e', 'l', ' ', 'b', 'y', ' ', 'wer', '-', 'L', 'y', 't', 'ton', ')', ',', ' ', 'w', 'her', 'e', ' ', 'Gaw', 't', 'r', 'y', ' ', 'say', 's', ':', ' ', '\\n', 'I', 'n', ' ', 'fin', 'e', ',', ' ', 'm', 'y', ' ', 'lif', 'e', ' is', ' ', 't', ' a ', 'g', 'r', 'e', 'a', 't', ' ', 's', 'c', 'h', 'o', 'o', 'l', 'boy', ',', ' ', 'tin', 'g', 'to ', 's', 'c', 'rap', 'e', 's', ' ', 'for', ' ', 't', ' it', ',', ' an', 'd', ' ', 'fig', 'h', 'tin', 'g', ' ', 'm', 'y', ' ', 'way', ' ', 'o', 'u', 't', ' as', ' ', 'bes', 't', ' as', ' ', 'I', ' ', 'can', '!', ' ', '\\n', 'I', 't', ' ', 'tin', 'u', 'e', 's', ' ', 'be ', 'u', 'sed', ' ', 'b', 'y', ' ', 'rep', 'u', 'le ', 'a', 'u', 't', 'hor', 's', ',', ' in', ' ', 'Wil', 'l', 'i', 'a', 'm', ' ', 'los', ' ', 'Wil', 'l', 'i', 'a', 'm', 's', \"'\", ' ', 'p', 'o', 'e', 'm', ' ', '1', '9', '1', '7', ' ', 'p', 'o', 'e', 'm', ' ', '\"', 'S', 'y', 'm', 'het', 'i', 'c', ' ', 'Por', 't', 'r', 'a', 'i', 't', ' a ', 'C', 'hil', 'd', '\"', ':', '\\n', 'A', 's', ' ', 'bes', 't', ' as', ' ', 's', 'can', ' ', '\\u2028', 's', 'hid', 'e', 's', ' ', 'sel', 'f', ' ', '\\u2028in', ' ', 't', 'ful', 'l', ' ', 'lig', 'h', 't', ' ', '\\n', 'But', ' ', 'w', 'hat', 'e', 'ver', ' ', 't', 'he ', 'o', 'rig', 'i', 'n', 's', ' an', 'd', ' ', 'tor', 'y', ' of', ' ', 't', 'con', 's', 't', 'ruc', 't', 'i', 'o', 'n', ',', ' ', 'han', \"'\", 's', ' ', 'ges', 't', 'i', 'o', 'n', ' ', 'mig', 'h', 't', ' ', 'hav', 'e', ' ', 'som', 'e', 't', 'hin', 'g', ' ', 'wit', 'h', ' ', 't', 'ces', ' ', 't', 'hat', ' ', 'k', 'e', 'e', 'p', ' in', ' ', 'ren', 't', ' us', 'e', '.', ' ', 'So ', 'I', ' ', 't', 'h', 'o', 'u', 'g', 'h', 't', ' ', 'I', \"'\", 'd', ' ', 'l', 'o', 'o', 'k', ' at', ' ', 'som', 'e', ' ', 'ren', 't', ' ', 'web', ' ', 'c', 'o', 'u', 'n', 't', 's', ';', ' an', 'd', ' ', 'fer', 'e', 'n', 't', ' ', 's', 'e', 'a', 'r', 'c', 'h', 'gin', 'e', 's', ' ', 'som', 'e', 'tim', 'e', 's', ' ', 'giv', 'e', ' ', 'c', 'o', 'u', 'n', 't', 's', ' ', 't', 'hat', ' ', ' in', ' ', 'dom', '-', 's', 'e', 'e', 'min', 'g', ' ', 'way', 's', ',', ' ', 'I', ' ', 't', 'r', 'i', 'e', 'd', ' ', 'M', 'S', 'N', ',', ' ', 'Yah', 'o', 'o', ' an', 'd', ' ', 'G', 'o', 'o', 'g', 'le.', ' ', 'I', ' ', 's', 'ted', ' ', 'b', 'y', ' ', 'l', 'o', 'o', 'kin', 'g', ' at', ' ', 't', 'ter', 'n', 's', ' ', '\"as', ' ', 'bes', 't', ' ', '_', '_', ' ', 'can', '\"', ' an', 'd', ' ', '\"as', ' ', 'bes', 't', ' as', ' ', '_', '_', ' ', 'can', '\"', ',', 'ros', 's', ' ', 't', 'fer', 'e', 'n', 't', ' ', 'p', 'ron', 'o', 'u', 'n', 's', '.', ' ', 'I', ' ', 'mig', 'h', 't', ' ', 's', 'til', 'l', ' ', 'cov', 'e', 'r', ' ', 'som', 'e', 't', 'hin', 'g', ' ', 'rel', 'e', 'van', 't', ' ', 'han', \"'\", 's', ' ', 'q', 'u', 'e', 's', 't', 'i', 'o', 'n', ',', ' ', ' al', 'o', 'n', 'g', ' ', 't', 'way', ' ', 'I', ' ', 's', 'tum', 'b', ' a ', 's', 't', 'ter', 'n', ' in', ' ', 't', 'web', ' ', 's', 'e', 'a', 'r', 'c', 'h', ' ', 'c', 'o', 'u', 'n', 't', ',', ' ', 'w', 'hic', 'h', ' ', 'I', \"'\", 'l', 'l', ' ', 's', 'har', 'e', ' ', 'wit', 'h', ' ', 'y', 'o', 'u', ' ', 'now', '.']\n"
     ]
    }
   ],
   "source": [
    "print ('TEXT:')\n",
    "\n",
    "print (raw)\n",
    "\n",
    "print ('TOKENIZED TEXT')\n",
    "\n",
    "pattern = '([^aeiou][aeiou][^aeiou])*'\n",
    "pattern1 = 'p[aeiou]{,2}t'\n",
    "print (nltk.regexp_tokenize(raw, pattern,pattern1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.Написати функцію unknown(), яка приймає інтернет адресу як аргумент і повертає не відомі слова, які зустрічаються в тексті. При розробці функції використовувати re.findall() для виявлення всіх підстрічок та корпус Words Corpus (nltk.corpus.words) для виявлення не відомих слів."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = re.findall(r\"[A-Za-z]+\",raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Прочитати Додаток А. Дослідити явища описані у Додатку А використовуючи корпуси текстів та метод findall()для пошуку в токенізованому тексті. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['as best I can', ' as best as I can']\n"
     ]
    }
   ],
   "source": [
    "print (re.findall(r\"as best\\s\\w\\s+can| as best as\\s+\\w+\\s+can\", raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
