{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13 var\n",
    "1\n",
    "2\n",
    "3\n",
    "4\n",
    "5\n",
    "7\n",
    "6\n",
    "9\n",
    "14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Напишіть функцію, яка приймає адресу URL, як аргумент, і повертає те що міститься за цією адресою з видаленням HTML розмітки. Використовувати urllib.urlopen для доступу до контенту наступним чином raw_contents = urllib.urlopen('http://www.nltk.org/').read()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\n<!DOCTYPE html>\\n\\n<html>\\n  <head>\\n    <meta charset=\"utf-8\" />\\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" /><meta name=\"generator\" content=\"Docutils 0.17: http://docutils.sourceforge.net/\" />\\n\\n    <title>Natural Language Toolkit &#8212; NLTK 3.6.2 documentation</title>\\n    <link rel=\"stylesheet\" href=\"_static/pygments.css\" type=\"text/css\" />\\n    <link rel=\"stylesheet\" href=\"_static/agogo.css\" type=\"text/css\" />\\n    <script id=\"documentation_options\" data-url_root=\"./\" src=\"_static/documentation_options.js\"></script>\\n    <script src=\"_static/jquery.js\"></script>\\n    <script src=\"_static/underscore.js\"></script>\\n    <script src=\"_static/doctools.js\"></script>\\n    <link rel=\"index\" title=\"Index\" href=\"genindex.html\" />\\n    <link rel=\"search\" title=\"Search\" href=\"search.html\" />\\n    <link rel=\"next\" title=\"NLTK News\" href=\"news.html\" /> \\n  </head><body>\\n    <div class=\"header-wrapper\" role=\"banner\">\\n      <div class=\"header\">\\n        <div class=\"headertitle\"><a\\n          href=\"#\">NLTK 3.6.2 documentation</a></div>\\n        <div class=\"rel\" role=\"navigation\" aria-label=\"related navigation\">\\n          <a href=\"news.html\" title=\"NLTK News\"\\n             accesskey=\"N\">next</a> |\\n          <a href=\"py-modindex.html\" title=\"Python Module Index\"\\n             >modules</a> |\\n          <a href=\"genindex.html\" title=\"General Index\"\\n             accesskey=\"I\">index</a>\\n        </div>\\n       </div>\\n    </div>\\n\\n    <div class=\"content-wrapper\">\\n      <div class=\"content\">\\n        <div class=\"document\">\\n            \\n      <div class=\"documentwrapper\">\\n        <div class=\"bodywrapper\">\\n          <div class=\"body\" role=\"main\">\\n            \\n  <section id=\"natural-language-toolkit\">\\n<h1>Natural Language Toolkit<a class=\"headerlink\" href=\"#natural-language-toolkit\" title=\"Permalink to this headline\">\\xc2\\xb6</a></h1>\\n<p>NLTK is a leading platform for building Python programs to work with human language data.\\nIt provides easy-to-use interfaces to <a class=\"reference external\" href=\"http://nltk.org/nltk_data/\">over 50 corpora and lexical\\nresources</a> such as WordNet,\\nalong with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning,\\nwrappers for industrial-strength NLP libraries,\\nand an active <a class=\"reference external\" href=\"http://groups.google.com/group/nltk-users\">discussion forum</a>.</p>\\n<p>Thanks to a hands-on guide introducing programming fundamentals alongside topics in computational linguistics, plus comprehensive API documentation,\\nNLTK is suitable for linguists, engineers, students, educators, researchers, and industry users alike.\\nNLTK is available for Windows, Mac OS X, and Linux. Best of all, NLTK is a free, open source, community-driven project.</p>\\n<p>NLTK has been called \\xe2\\x80\\x9ca wonderful tool for teaching, and working in, computational linguistics using Python,\\xe2\\x80\\x9d\\nand \\xe2\\x80\\x9can amazing library to play with natural language.\\xe2\\x80\\x9d</p>\\n<p><a class=\"reference external\" href=\"http://nltk.org/book\">Natural Language Processing with Python</a> provides a practical\\nintroduction to programming for language processing.\\nWritten by the creators of NLTK, it guides the reader through the fundamentals\\nof writing Python programs, working with corpora, categorizing text, analyzing linguistic structure,\\nand more.\\nThe online version of the book has been been updated for Python 3 and NLTK 3.\\n(The original Python 2 version is still available at <a class=\"reference external\" href=\"http://nltk.org/book_1ed\">http://nltk.org/book_1ed</a>.)</p>\\n<section id=\"some-simple-things-you-can-do-with-nltk\">\\n<h2>Some simple things you can do with NLTK<a class=\"headerlink\" href=\"#some-simple-things-you-can-do-with-nltk\" title=\"Permalink to this headline\">\\xc2\\xb6</a></h2>\\n<p>Tokenize and tag some text:</p>\\n<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">import</span> <span class=\"nn\">nltk</span>\\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sentence</span> <span class=\"o\">=</span> <span class=\"s2\">&quot;&quot;&quot;At eight o&#39;clock on Thursday morning</span>\\n<span class=\"gp\">... </span><span class=\"s2\">Arthur didn&#39;t feel very good.&quot;&quot;&quot;</span>\\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">tokens</span> <span class=\"o\">=</span> <span class=\"n\">nltk</span><span class=\"o\">.</span><span class=\"n\">word_tokenize</span><span class=\"p\">(</span><span class=\"n\">sentence</span><span class=\"p\">)</span>\\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">tokens</span>\\n<span class=\"go\">[&#39;At&#39;, &#39;eight&#39;, &quot;o&#39;clock&quot;, &#39;on&#39;, &#39;Thursday&#39;, &#39;morning&#39;,</span>\\n<span class=\"go\">&#39;Arthur&#39;, &#39;did&#39;, &quot;n&#39;t&quot;, &#39;feel&#39;, &#39;very&#39;, &#39;good&#39;, &#39;.&#39;]</span>\\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">tagged</span> <span class=\"o\">=</span> <span class=\"n\">nltk</span><span class=\"o\">.</span><span class=\"n\">pos_tag</span><span class=\"p\">(</span><span class=\"n\">tokens</span><span class=\"p\">)</span>\\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">tagged</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">:</span><span class=\"mi\">6</span><span class=\"p\">]</span>\\n<span class=\"go\">[(&#39;At&#39;, &#39;IN&#39;), (&#39;eight&#39;, &#39;CD&#39;), (&quot;o&#39;clock&quot;, &#39;JJ&#39;), (&#39;on&#39;, &#39;IN&#39;),</span>\\n<span class=\"go\">(&#39;Thursday&#39;, &#39;NNP&#39;), (&#39;morning&#39;, &#39;NN&#39;)]</span>\\n</pre></div>\\n</div>\\n<p>Identify named entities:</p>\\n<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">entities</span> <span class=\"o\">=</span> <span class=\"n\">nltk</span><span class=\"o\">.</span><span class=\"n\">chunk</span><span class=\"o\">.</span><span class=\"n\">ne_chunk</span><span class=\"p\">(</span><span class=\"n\">tagged</span><span class=\"p\">)</span>\\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">entities</span>\\n<span class=\"go\">Tree(&#39;S&#39;, [(&#39;At&#39;, &#39;IN&#39;), (&#39;eight&#39;, &#39;CD&#39;), (&quot;o&#39;clock&quot;, &#39;JJ&#39;),</span>\\n<span class=\"go\">           (&#39;on&#39;, &#39;IN&#39;), (&#39;Thursday&#39;, &#39;NNP&#39;), (&#39;morning&#39;, &#39;NN&#39;),</span>\\n<span class=\"go\">       Tree(&#39;PERSON&#39;, [(&#39;Arthur&#39;, &#39;NNP&#39;)]),</span>\\n<span class=\"go\">           (&#39;did&#39;, &#39;VBD&#39;), (&quot;n&#39;t&quot;, &#39;RB&#39;), (&#39;feel&#39;, &#39;VB&#39;),</span>\\n<span class=\"go\">           (&#39;very&#39;, &#39;RB&#39;), (&#39;good&#39;, &#39;JJ&#39;), (&#39;.&#39;, &#39;.&#39;)])</span>\\n</pre></div>\\n</div>\\n<p>Display a parse tree:</p>\\n<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">nltk.corpus</span> <span class=\"kn\">import</span> <span class=\"n\">treebank</span>\\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">t</span> <span class=\"o\">=</span> <span class=\"n\">treebank</span><span class=\"o\">.</span><span class=\"n\">parsed_sents</span><span class=\"p\">(</span><span class=\"s1\">&#39;wsj_0001.mrg&#39;</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">t</span><span class=\"o\">.</span><span class=\"n\">draw</span><span class=\"p\">()</span>\\n</pre></div>\\n</div>\\n<img alt=\"_images/tree.gif\" src=\"_images/tree.gif\" />\\n<p>NB. If you publish work that uses NLTK, please cite the NLTK book as\\nfollows:</p>\\n<blockquote>\\n<div><p>Bird, Steven, Edward Loper and Ewan Klein (2009), <em>Natural Language Processing with Python</em>.  O\\xe2\\x80\\x99Reilly Media Inc.</p>\\n</div></blockquote>\\n</section>\\n<section id=\"next-steps\">\\n<h2>Next Steps<a class=\"headerlink\" href=\"#next-steps\" title=\"Permalink to this headline\">\\xc2\\xb6</a></h2>\\n<ul class=\"simple\">\\n<li><p><a class=\"reference external\" href=\"http://groups.google.com/group/nltk\">sign up for release announcements</a></p></li>\\n<li><p><a class=\"reference external\" href=\"http://groups.google.com/group/nltk-users\">join in the discussion</a></p></li>\\n</ul>\\n</section>\\n</section>\\n<section id=\"contents\">\\n<h1>Contents<a class=\"headerlink\" href=\"#contents\" title=\"Permalink to this headline\">\\xc2\\xb6</a></h1>\\n<div class=\"toctree-wrapper compound\">\\n<ul>\\n<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"news.html\">NLTK News</a></li>\\n<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"install.html\">Installing NLTK</a></li>\\n<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"data.html\">Installing NLTK Data</a></li>\\n<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"contribute.html\">Contribute to NLTK</a></li>\\n<li class=\"toctree-l1\"><a class=\"reference external\" href=\"https://github.com/nltk/nltk/wiki/FAQ\">FAQ</a></li>\\n<li class=\"toctree-l1\"><a class=\"reference external\" href=\"https://github.com/nltk/nltk/wiki\">Wiki</a></li>\\n<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"api/nltk.html\">API</a></li>\\n<li class=\"toctree-l1\"><a class=\"reference external\" href=\"http://www.nltk.org/howto\">HOWTO</a></li>\\n</ul>\\n</div>\\n<ul class=\"simple\">\\n<li><p><a class=\"reference internal\" href=\"genindex.html\"><span class=\"std std-ref\">Index</span></a></p></li>\\n<li><p><a class=\"reference internal\" href=\"py-modindex.html\"><span class=\"std std-ref\">Module Index</span></a></p></li>\\n<li><p><a class=\"reference internal\" href=\"search.html\"><span class=\"std std-ref\">Search Page</span></a></p></li>\\n</ul>\\n</section>\\n\\n\\n            <div class=\"clearer\"></div>\\n          </div>\\n        </div>\\n      </div>\\n        </div>\\n        <div class=\"sidebar\">\\n          \\n          <h3>Table of Contents</h3>\\n          <ul>\\n<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"news.html\">NLTK News</a></li>\\n<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"install.html\">Installing NLTK</a></li>\\n<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"data.html\">Installing NLTK Data</a></li>\\n<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"contribute.html\">Contribute to NLTK</a></li>\\n<li class=\"toctree-l1\"><a class=\"reference external\" href=\"https://github.com/nltk/nltk/wiki/FAQ\">FAQ</a></li>\\n<li class=\"toctree-l1\"><a class=\"reference external\" href=\"https://github.com/nltk/nltk/wiki\">Wiki</a></li>\\n<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"api/nltk.html\">API</a></li>\\n<li class=\"toctree-l1\"><a class=\"reference external\" href=\"http://www.nltk.org/howto\">HOWTO</a></li>\\n</ul>\\n\\n          <div role=\"search\">\\n            <h3 style=\"margin-top: 1.5em;\">Search</h3>\\n            <form class=\"search\" action=\"search.html\" method=\"get\">\\n                <input type=\"text\" name=\"q\" />\\n                <input type=\"submit\" value=\"Go\" />\\n            </form>\\n          </div>\\n\\n        </div>\\n        <div class=\"clearer\"></div>\\n      </div>\\n    </div>\\n\\n    <div class=\"footer-wrapper\">\\n      <div class=\"footer\">\\n        <div class=\"left\">\\n          <div role=\"navigation\" aria-label=\"related navigaton\">\\n            <a href=\"news.html\" title=\"NLTK News\"\\n              >next</a> |\\n            <a href=\"py-modindex.html\" title=\"Python Module Index\"\\n              >modules</a> |\\n            <a href=\"genindex.html\" title=\"General Index\"\\n              >index</a>\\n          </div>\\n          <div role=\"note\" aria-label=\"source link\">\\n              <br/>\\n              <a href=\"_sources/index.rst.txt\"\\n                rel=\"nofollow\">Show Source</a>\\n          </div>\\n        </div>\\n\\n        <div class=\"right\">\\n          \\n    <div class=\"footer\" role=\"contentinfo\">\\n        &#169; Copyright 2021, NLTK Project.\\n      Last updated on Apr 20, 2021.\\n      Created using <a href=\"https://www.sphinx-doc.org/\">Sphinx</a> 3.5.2.\\n    </div>\\n        </div>\\n        <div class=\"clearer\"></div>\\n      </div>\\n    </div>\\n\\n  </body>\\n</html>'\n"
     ]
    }
   ],
   "source": [
    "import urllib.request # імпорт бібліотекі повернення\n",
    "\n",
    "with urllib.request.urlopen(\"http://www.nltk.org\") as url: # звернення до сайту\n",
    "    s = url.read() # читання\n",
    "    # I'm guessing this would output the html source code ?\n",
    "    print(s) # друк"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Збережіть деякий текст у файлі corpus.txt. Визначити функцію load(f) для читання файлу, назва якого є її аргументом і повертає стрічку, яка містить текст з файлу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(f): # функція\n",
    "    a = open(f) # відкрити текст\n",
    "    raw = a.read() # прочитати текст\n",
    "    return raw # повернути"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'So, at the start of 2012, I set myself the challenge of trying to read a book from every country (well, all 195 UN-recognised states plus former UN member Taiwan) in a year to find out what I was missing.cat pat\\n1234567890\\n(2*3+8)\\n5*2+2\\nA few days ago, Nathan Bierma asked me (by email) whether the construction exemplified by \"as best (as) I can\" might be a blend of \"the best (that) I can\" and \"as well as I can\". The puzzle is why we say \"as best (as) I can\", but not \"as hardest (as) I can\", or indeed \"as ___ (as) I can\" for any other superlative. \\nWhatever the exact history, \"as best <SUBJ> <MODAL>\" is an old pattern. For instance, an anonymous drama from 1634, \"The Mirror of New Reformation\", has the lines\\n... I wil straight dispose, \\u2028as best I can, th\\'inferiour Magistrate ... \\nAnd in \"The Taming of the Shrew\" (1594), Shakespeare has Petruchio say\\nAnd I haue thrust my selfe into this maze, \\u2028Happily to wiue and thriue, as best I may ... \\nThe pattern \"as best as\" seems to be more recent. The earlier citation I could find was from 1856, in \"Night and Morning\" (a play adapted from the novel by Bulwer-Lytton), where Gawtry says: \\nIn fine, my life is that of a great schoolboy, getting into scrapes for the fun of it, and fighting my way out as best as I can! \\nIt continues to be used by reputable authors, as in William Carlos Williams\\' poem 1917 poem \"Sympathetic Portrait of a Child\":\\nAs best as she can \\u2028she hides herself \\u2028in the full sunlight \\nBut whatever the origins and history of the construction, Nathan\\'s suggestion might have something to do with the forces that keep it in current use. So I thought I\\'d look at some current web counts; and since different search engines sometimes give counts that differ in random-seeming ways, I tried MSN, Yahoo and Google. I started by looking at the patterns \"as best __ can\" and \"as best as __ can\", across the different pronouns. I might still discover something relevant to Nathan\\'s question, but along the way I stumbled on a strange pattern in the web search count, which I\\'ll share with you now.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load('corpus.txt') # ввід тексту"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Перепишіть наступний цикл як list comprehension: \t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'The': 3, 'dog': 3, 'gave': 4, 'John': 4, 'the': 3, 'newspaper': 9}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{sent: len(sent) for sent in ('The', 'dog', 'gave', 'John', 'the', 'newspaper')}  # переписання циклу \n",
    "# який вивовдить текст і його дліна"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Перевірити різницю між стрічками і цілим виконавши наступні дії: \"3\" * 7 та 3 * 7. Спробуйте здійснити конвертування між стрічками і цілими використавши int(\"3\") та str(3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3333333'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'3' * 7 # множення стрічки 3 на цифру 7(так як це текст то він просто дубляється стільки раз на скільки множеться)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 * 7 # множення 3 на 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int('3') * 7 # множення чисел"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3333333'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(3) * 7 # множення строки на число"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Змінна \"3\" є стрічкового характеру, тому помноживши її на 7, отримуємо у 7 разів довшу стрічку. Відповідно функція int(\"3\") перетворює стрічкову змінну в цілочисельну, а функція str(3) перетворює цілочисельну змінну в стрічкову. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Що станеться, коли стрічки форматування %6s та %-6s використовується для відображення стрічки довшої ніж 6 символів?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(  LOVE)\n"
     ]
    }
   ],
   "source": [
    "print(\"(%6s)\" %  \"LOVE\") # %6s для стрічок довжиною до шести символів виконує форматування по лівому краю "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(love  )\n"
     ]
    }
   ],
   "source": [
    "print(\"(%-6s)\" %  \"love\") #%-6s – форматування по правому краю"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(interpreter)\n"
     ]
    }
   ],
   "source": [
    "print(\"(%6s)\" %  \"interpreter\") # %6s для стрічок довжиною до шести символів виконує форматування по лівому краю "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(interpreter)\n"
     ]
    }
   ],
   "source": [
    "print(\"(%-6s)\" %  \"interpreter\") # %-6s – форматування по правому краю"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стрічка %6s для стрічок довжиною до шести символів виконує форматування по лівому краю (тобто додає пробіли), а стрічка %-6s – форматування по правому краю. Коли ж стрічка довша за 6 символів, форматування не відбувається. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Створіть файл, який буде містити слова та їх частоту записані в окремих рядках через пробіл (fuzzy 53). Прочитайте цей файл, використовуючи open(filename).readlines().  Розділіть кожну стрічку на дві частини, використовуючи split(), і перетворіть число в ціле значення використовуючи int(). Результат має бути у вигляді списку: [['fuzzy', 53], ...]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello 1 \\n', 'wow 2 \\n', 'lol 3 \\n', 'all 4 right 5 \\n', 'good 6']\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division # виклик псеводо функіцї\n",
    "import nltk, re, pprint # вилік бібліотек\n",
    "file1 = open(\"l5f.txt\").readlines() # відкривання файлу та читання по стрічках\n",
    "print(file1) # друк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['hello', 1], ['wow', 2], ['lol', 3], ['all', 4], ['good', 6]]\n"
     ]
    }
   ],
   "source": [
    "text = file1 \n",
    "list = [] # пустий список\n",
    "for element in text: # цикл перебору\n",
    "    list.append([element.split()[0], int(element.split()[1])]) # засунення все в ліст та розбивання\n",
    "print(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Прочитайте деякий текст з корпуса, здійсніть його токенізацію і збережіть у список всі wh-слова, які в ньому зустрічаються.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "import nltk # імпорт бібліотек\n",
    "from nltk.corpus import gutenberg # імпорт набору текстів\n",
    "print(gutenberg.fileids()) # набір текстів"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['who', 'who', 'what', 'where', 'which', 'when', 'what', 'why', 'whose', 'whisper', 'which', 'who', 'which', 'which', 'which', 'where', 'which', 'when', 'wholsome', 'what', 'whole', 'which', 'what', 'whence', 'which', 'what', 'whose', 'who', 'which', 'whereof', 'why', 'what', 'which', 'what', 'what', 'what', 'where', 'while', 'whilst', 'where', 'where', 'when', 'whatsoeuer', 'whole', 'which', 'what', 'what', 'which', 'why', 'why', 'wherefore', 'what', 'what', 'what', 'what', 'what', 'what', 'when', 'whose', 'whole', 'what', 'whose', 'whose', 'whose', 'wholsome', 'what', 'while', 'what', 'what', 'what', 'what', 'who', 'what', 'where', 'what', 'what', 'where', 'what', 'what', 'whom', 'where', 'what', 'which', 'whereat', 'which', 'what', \"whil'st\", 'white', 'whilst', 'what', 'what', 'whereon', 'where', 'who', 'which', 'what', 'which', 'which', 'what', 'what', 'whether', 'why', 'wherefore', 'why', 'what', 'when', 'what', 'whose', 'what', 'when', 'while', 'while', 'which', 'what', 'when', 'what', 'which', 'where', 'when', 'whose', 'where', 'whose', 'where', 'whiffe', 'wheele', 'who', 'who', 'where', 'while', 'who', 'whipping', 'which', 'what', 'whole', 'whole', 'whose', 'why', 'what', 'what', 'who', 'whose', 'when', 'what', 'what', 'what', 'what', 'what', 'what', 'which', 'which', 'what', 'where', 'who', 'whipt', 'whose', 'which', 'whole', 'what', 'what', 'when', \"whil'st\", 'what', 'what', 'whose', 'what', 'what', 'what', 'who', 'what', 'what', 'when', 'what', 'who', 'who', 'where', 'when', 'what', 'while', 'what', 'wholsome', 'while', 'whole', 'whole', 'what', 'wholsome', 'wholsome', 'what', 'when', 'while', 'why', 'what', 'whose', 'wheele', 'whose', 'which', 'when', 'what', 'where', 'what', 'white', 'what', 'what', 'which', 'what', 'what', 'when', 'who', 'whereto', 'what', 'what', 'what', 'what', 'what', 'what', 'wholsom', 'what', 'where', 'whet', 'what', 'who', 'where', 'which', 'what', 'what', 'when', 'who', 'what', 'when', 'whips', 'whose', 'what', 'whom', 'what', 'what', 'what', 'whereto', 'where', 'what', 'what', 'when', 'what', 'where', 'where', 'where', 'where', 'where', 'where', 'which', 'which', 'what', 'what', 'what', 'when', 'what', 'whispers', 'which', 'what', 'what', 'what', 'what', 'where', 'wheele', 'when', 'white', 'whom', 'where', 'what', 'what', 'where', 'whom', 'which', 'which', 'where', 'which', 'what', 'what', 'what', 'when', 'whereon', 'where', 'while', 'what', 'when', 'when', 'when', 'which', 'which', 'when', 'why', 'where', 'why', 'whose', 'why', 'what', 'while', 'whoreson', 'what', 'why', 'whereto', 'which', 'while', 'while', 'whose', 'whose', 'what', 'what', 'whine', 'what', 'where', 'what', 'wheaten', 'what', 'when', 'what', 'whor', 'who', 'what', 'which', 'why', 'what', 'which', 'whit', 'what', 'when', 'which', 'what', 'what', 'whiles', 'which']\n"
     ]
    }
   ],
   "source": [
    "text = gutenberg.raw('shakespeare-hamlet.txt') # відкрити текст хамлет\n",
    "tokens = nltk.word_tokenize(text) # токінізувати текст\n",
    "wh_words = [w.lower() for w in tokens if w.startswith('wh')] # прирівняти усе до малих літер там перевірити чи вони\n",
    "# починаются на ВХ\n",
    "print(wh_words) # ДРУК РЕЗУЛЬТАТУ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup # імпорт бібліотеки для парсингу\n",
    "import urllib3 # імпорт модуля для відкривання юрл \n",
    "\n",
    "http = urllib3.PoolManager() # відкриває довільні запити\n",
    "\n",
    "url = 'http://www.gutenberg.org/files/2554/2554-0.txt' # відкриває посилання\n",
    "response = http.request('GET', url) # відправляє запит \n",
    "raw = str(response.data) # відповідь\n",
    "type(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(raw) #  токінізування"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"b'\\\\xef\\\\xbb\\\\xbfThe\",\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'Crime',\n",
       " 'and',\n",
       " 'Punishment',\n",
       " ',',\n",
       " 'by']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:10] # вивід 10 елемнтів"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.Text(tokens) #  текст токін"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.text.Text"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"b'\\\\xef\\\\xbb\\\\xbfThe\",\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'Crime',\n",
       " 'and',\n",
       " 'Punishment',\n",
       " ',',\n",
       " 'by']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:10] #  вивід 10 елементів"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Katerina Ivanovna; Pyotr Petrovitch; Avdotya Romanovna; Pulcheria\n",
      "Alexandrovna; Rodion Romanovitch; Marfa Petrovna; \\xe2\\x80\\x9d cried;\n",
      "Sofya Semyonovna; \\xe2\\x80\\x9d said; old woman; \\xe2\\x80\\x9d\n",
      "Raskolnikov; Porfiry Petrovitch; Project Gutenberg-tm;\n",
      "don\\xe2\\x80\\x99t know; great deal; Amalia Ivanovna; young man; Hay\n",
      "Market; police station; Nikodim Fomitch\n"
     ]
    }
   ],
   "source": [
    "text.collocations() #  колокація"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5866"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.find(\"PART I\") #  вивід частини 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14 Доступіться до текстів ABC Rural News та ABC Science News з корпуса (nltk.corpus.abc). Знайдіть значення для оцінки читабельності текстів (аналогічно до задачі №12). Використовуйте Punkt для поділу тексту на окремі речення.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rural.txt', 'science.txt']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import abc #  імпорт елементу корпус абс\n",
    "abc.fileids() # Виводіть елементи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fileid in abc.fileids(): #\n",
    "    ari = (4.71 * (len(abc.raw(fileid))/len(abc.words(fileid))) + (0.5 * (len(abc.words(fileid))/ len(abc.sents(fileid))))\n",
    "          - 21.43)# підрахунки за аналогом 12 задачі\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.819500428517806 science.txt\n"
     ]
    }
   ],
   "source": [
    "print(ari, fileid) # друк результатів по тексту"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
